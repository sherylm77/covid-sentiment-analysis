{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "annotation_list = [\"Tweet Annotations - Feb Translated Annotations.tsv\"]\n",
    "annotation_list.append(\"Tweet Annotations - Mar Translated Annotations.tsv\")\n",
    "annotation_list.append(\"Tweet Annotations - Apr Translated Annotations.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\steffi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\steffi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\steffi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk>=3.1->textblob) (4.58.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\steffi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n",
      "Requirement already satisfied: regex in c:\\users\\steffi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk>=3.1->textblob) (2020.11.13)\n",
      "Requirement already satisfied: click in c:\\users\\steffi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Transfer the contents of a tsv file to a list for easier access\n",
    "!pip3 install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "def tsv_to_list(annotation_file, sentiment=False):\n",
    "    annotation_list = []\n",
    "    annotation = open(annotation_file, encoding='utf-8')\n",
    "    read_tsv = csv.reader(annotation, delimiter=\"\\t\") \n",
    "    for row in read_tsv:\n",
    "        if row[2] != '':\n",
    "            text = TextBlob(row[2])\n",
    "            if sentiment:\n",
    "                annotation_list.append([row[0], row[1], row[2], text.sentiment.polarity])\n",
    "            else:\n",
    "                annotation_list.append(row)\n",
    "    print(len(annotation_list))\n",
    "    return annotation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the label for each verse for one annotator\n",
    "# N: -1, N+NU: -0.5, NU: 0, P+NU: 0.5, P: 1\n",
    "def get_labels_for(annotation):\n",
    "    tweets_and_labels = []\n",
    "    row_num = 0\n",
    "    for row in annotation:\n",
    "        if row_num == 0:\n",
    "            row_num += 1\n",
    "            continue\n",
    "        if row[15] != '': # don't use unsure\n",
    "            row_num += 1\n",
    "            continue\n",
    "            #print(\"not using unsure row\", row_num+1)\n",
    "        if 'UNUSABLE' in row[16].upper() or 'NOT ENOUGH INFO' in row[16].upper():\n",
    "            row_num += 1\n",
    "            continue\n",
    "            #print(\"unusable row\", row_num+1)\n",
    "        elif row[6].upper() == 'X' and (row[8].upper() != 'X' and row[7].upper() == 'X'): # don't use pos + neg mixed labels\n",
    "            row_num += 1\n",
    "            continue\n",
    "            #print(\"not using pos+neg row\", row_num+1)\n",
    "        elif row[6].upper() == 'X' and (row[7].upper() != 'X' and row[8].upper() != 'X'): # only pos\n",
    "            new_row = [annotation[row_num][0], annotation[row_num][1], annotation[row_num][2], annotation[row_num][3], annotation[row_num][4], annotation[row_num][5], 1]\n",
    "            tweets_and_labels.append(new_row)\n",
    "        #elif row[6].upper() == 'X' and (row[8].upper() == 'X' and row[7].upper() != 'X'): # pos + neu\n",
    "        #    new_row = [annotation[row_num][0], annotation[row_num][1], annotation[row_num][2], annotation[row_num][3], annotation[row_num][4], annotation[row_num][5], 3]\n",
    "        #    tweets_and_labels.append(new_row)\n",
    "        elif row[8].upper() == 'X' and (row[6].upper() != 'X' and row[7].upper() != 'X'): # only neu \n",
    "            new_row = [annotation[row_num][0], annotation[row_num][1], annotation[row_num][2], annotation[row_num][3], annotation[row_num][4], annotation[row_num][5], 0]\n",
    "            tweets_and_labels.append(new_row)\n",
    "        elif row[7].upper() == 'X' and (row[8].upper() != 'X' and row[6].upper() != 'X'): # only neg\n",
    "            new_row = [annotation[row_num][0], annotation[row_num][1], annotation[row_num][2], annotation[row_num][3], annotation[row_num][4], annotation[row_num][5], -1]\n",
    "            tweets_and_labels.append(new_row)\n",
    "        #elif row[8].upper() == 'X' and (row[7].upper() == 'X' and row[6].upper() != 'X'): # neg + neu\n",
    "        #    new_row = [annotation[row_num][0], annotation[row_num][1], annotation[row_num][2], annotation[row_num][3], annotation[row_num][4], annotation[row_num][5], 2]\n",
    "        #    tweets_and_labels.append(new_row) \n",
    "        #else:\n",
    "        #    print(\"outlier row:\", row_num+1)\n",
    "        row_num += 1\n",
    "    return tweets_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769 925\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1371 entries, 0 to 1370\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   tweetText       1371 non-null   object\n",
      " 1   tweetSentiment  1371 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 32.1+ KB\n"
     ]
    }
   ],
   "source": [
    "feb_list = tsv_to_list(annotation_list[0])\n",
    "feb_labels = get_labels_for(feb_list)\n",
    "mar_list = tsv_to_list(annotation_list[1])\n",
    "mar_labels = get_labels_for(mar_list)\n",
    "apr_list = tsv_to_list(annotation_list[2])\n",
    "apr_labels = get_labels_for(apr_list)\n",
    "\n",
    "all_labels = feb_labels + mar_labels + apr_labels\n",
    "#print(all_labels.count(-1), all_labels.count(0), all_labels.count(1))\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(all_labels, columns=['tweetID', 'tweetTime', 'tweetText', 'tweetLang', 'tweetCoordinates', 'tweetPlace', 'tweetSentiment'])\n",
    "data.head()\n",
    "\n",
    "tweets_labels = pd.DataFrame(index=None, columns=['tweetText', 'tweetSentiment'])\n",
    "positive_count = 0\n",
    "neutral_count = 0\n",
    "\n",
    "for i in range(len(data.index)):\n",
    "    if data.at[i, 'tweetSentiment'] == 1:\n",
    "        positive_count += 1\n",
    "    if data.at[i, 'tweetSentiment'] == 0:\n",
    "        neutral_count += 1\n",
    "\n",
    "print(positive_count, neutral_count)\n",
    "\n",
    "neg_count = 0\n",
    "for i in range(len(data.index)):\n",
    "    if neg_count < neutral_count:\n",
    "        if data.at[i, 'tweetSentiment'] == -1:\n",
    "            neg_count += 1\n",
    "            tweets_labels.loc[len(tweets_labels.index)] = [data.at[i, 'tweetText'], data.at[i, 'tweetSentiment']]\n",
    "        else:\n",
    "            tweets_labels.loc[len(tweets_labels.index)] = [data.at[i, 'tweetText'], data.at[i, 'tweetSentiment']]\n",
    "            \n",
    "tweets_labels.info()\n",
    "#test_data = pd.DataFrame(apr_labels, columns=['tweetID', 'tweetTime', 'tweetText', 'tweetLang', 'tweetCoordinates', 'tweetPlace', 'tweetSentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       I love to look at people's opinions about the ...\n",
      "1       The latest The AmericanAwaken ing Daily PM!  T...\n",
      "2       #Macau casinos will be closed for half a month...\n",
      "3       Social media conspiracies blame coronavirus on...\n",
      "4       Coronavirus, official: patient zero has nothin...\n",
      "                              ...                        \n",
      "1366    Coachella music festival postponed over corona...\n",
      "1367    If later one messes with the gypsies of the 30...\n",
      "1368    That's the whole point! Here is his moment to ...\n",
      "1369    Sumo: March tournament to be held behind close...\n",
      "1370    @guardian No, I'm pretty sure it's just becaus...\n",
      "Name: tweetText, Length: 1371, dtype: object\n",
      "1371\n",
      "1371\n"
     ]
    }
   ],
   "source": [
    "# Get all the words from the data\n",
    "import random\n",
    "\n",
    "text = []\n",
    "for tweet in tweets_labels['tweetText']:\n",
    "    text.append(tweet.split())\n",
    "print(len(text))\n",
    "\n",
    "tweets_and_labels = []\n",
    "tweet_count = 0\n",
    "for label in tweets_labels['tweetSentiment']:\n",
    "    if tweet_count < len(tweets_labels['tweetSentiment']):\n",
    "        tweets_and_labels.append((text[tweet_count], label))\n",
    "        tweet_count += 1\n",
    "print(len(tweets_and_labels))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(tweets_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'love', 'to', 'look', 'at', \"people's\", 'opinions', 'about', 'the', 'coronavirus', 'because', 'can', 'find', 'both', 'memes', 'and', 'people', 'who', 'believe', 'that']\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "\n",
    "for sent in text:\n",
    "    for w in sent:\n",
    "        all_words.append(w.lower())\n",
    "\n",
    "all_words = FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "print(word_features[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "        #print(w, \":\", features[w])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(find_features(tweet), category) for (tweet, category) in tweets_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1233\n"
     ]
    }
   ],
   "source": [
    "cutoff = round(len(tweets_and_labels)*0.9) - 1\n",
    "training_set = featuresets[:cutoff]\n",
    "testing_set = featuresets[cutoff:]\n",
    "print(cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 59.42028985507246\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier accuracy percent:\",(accuracy(classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = 'Just 9 cases, 7 of them linked, from 60,000 tests! Outstanding! NSW absolutely smashing it  Thanks so much to our brilliant contact tracers'\n",
    "classifier.classify(find_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                negative = True                1 : -1     =     16.4 : 1.0\n",
      "                 contain = True                1 : -1     =     12.8 : 1.0\n",
      "             temperature = True                1 : -1     =     12.8 : 1.0\n",
      "                   fight = True                1 : -1     =     11.7 : 1.0\n",
      "                    2019 = True                0 : -1     =      9.9 : 1.0\n",
      "                   areas = True                1 : -1     =      9.1 : 1.0\n",
      "                    care = True                1 : -1     =      9.1 : 1.0\n",
      "                carrying = True                1 : -1     =      9.1 : 1.0\n",
      "            coronavirus\" = True                1 : -1     =      9.1 : 1.0\n",
      "                  demand = True                1 : -1     =      9.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       100 non-null    object\n",
      " 1   sentiment  100 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.3+ KB\n"
     ]
    }
   ],
   "source": [
    "nov_list = tsv_to_list('Tweet Annotations - Nov Translated.tsv')\n",
    "results = pd.DataFrame(index=None, columns=['text', 'sentiment'])\n",
    "count = 0\n",
    "for row in nov_list:\n",
    "    tweetText = row[2]\n",
    "    sentiment = classifier.classify(find_features(tweetText.split()))\n",
    "    results.loc[len(results.index)] = [tweetText, sentiment]\n",
    "    count += 1\n",
    "    if count == 100:\n",
    "        break\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Election: Biden pledges to work for unity and ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Sindh reports 1,276 new cases, highest daily i...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Despite the challenges we face because of the ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wuhan's atmosphere is inundated with #WuhanVir...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1of2. This like what happened 2 me with our He...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Why does the early Nov COVID map mirror the el...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Magnesium plays an extremely important role in...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>if not enough coronavirus, burning and all the...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Media is unhinged knowing nothing can stop wha...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>@rtenews Such rubbish. People can't be punish ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>The spread of coronavirus is based on two fact...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Coronavirus kills a young Turin mother: Chiara...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tweetText</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Shifa malam alone has corona-worry!</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1 Year Since Coronavirus Outbreak: 1 Bichr Aag...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@Scouse_ma It's the only time COVID-19 gets a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020 Pentagon study: Flu vaccines increase ris...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>@SharonAll_In @hughjorgen921 @Jim_Jordan God b...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The number of health professionals infected by...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>@kyodo_official @jcp_cc Zhen Xia nimasukuGuan ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Mind blown</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Coronavirus: a study reveals that immunity aga...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Holy crap because Cuomo won't allow it.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>@ProfIgorRudan Yes, every state is a own natio...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Time they were  scrutinised and challenged pol...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Hopefully those jaker assholes. Koreans and Ch...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Dolphins will play Chargers without four assis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Coronavirus updates: Thanksgiving NFL games re...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Andrew Cuomo, who has been far from perfect in...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#aerosoles #Coronavirus # COVID19 #Spain #Cata...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Justice for her. This is insane and inhuman Ma...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I wore a mask and still got #COVID19!  Stupid ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Ontario reports record-high 1,588 new COVID-19...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>@gust_avius @firefoxx66 What is happening in #...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CM ghlot bole- Covid-19 ke lihaaj se cunautii ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweetText</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>If a family member has been diagnosed with #Co...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BBC News: Chuck Grassley: Senior Republican se...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Putin at the BRICS summit: &amp;quot;It is crucial...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Trump-loving pastor contracts COVID-19 after s...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>China accounts for 95 percent of U.S. imports ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>While over nine in 10 Canadians said they are ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Regina perseveres as COVID-19 downsizes Rememb...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I hate THIS ENTIRE FAMILY</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>can they cancel every other music show next it...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Here's Everything You Need To Know About BC's ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OMG</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Well, gentlemen with money will always have th...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Unbridled capitalism creates sociopaths.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>A great museum to support!</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment\n",
       "37  Election: Biden pledges to work for unity and ...        -1\n",
       "44  Sindh reports 1,276 new cases, highest daily i...        -1\n",
       "47  Despite the challenges we face because of the ...        -1\n",
       "14  Wuhan's atmosphere is inundated with #WuhanVir...        -1\n",
       "53  1of2. This like what happened 2 me with our He...        -1\n",
       "82  Why does the early Nov COVID map mirror the el...         0\n",
       "75  Magnesium plays an extremely important role in...        -1\n",
       "17  if not enough coronavirus, burning and all the...        -1\n",
       "50  Media is unhinged knowing nothing can stop wha...        -1\n",
       "42  @rtenews Such rubbish. People can't be punish ...        -1\n",
       "46  The spread of coronavirus is based on two fact...        -1\n",
       "6   Coronavirus kills a young Turin mother: Chiara...        -1\n",
       "39                                          tweetText        -1\n",
       "29                Shifa malam alone has corona-worry!        -1\n",
       "49  1 Year Since Coronavirus Outbreak: 1 Bichr Aag...        -1\n",
       "8   @Scouse_ma It's the only time COVID-19 gets a ...         0\n",
       "32  2020 Pentagon study: Flu vaccines increase ris...        -1\n",
       "76  @SharonAll_In @hughjorgen921 @Jim_Jordan God b...        -1\n",
       "9   The number of health professionals infected by...        -1\n",
       "95  @kyodo_official @jcp_cc Zhen Xia nimasukuGuan ...        -1\n",
       "86                                         Mind blown        -1\n",
       "63  Coronavirus: a study reveals that immunity aga...        -1\n",
       "56            Holy crap because Cuomo won't allow it.        -1\n",
       "34  @ProfIgorRudan Yes, every state is a own natio...        -1\n",
       "71  Time they were  scrutinised and challenged pol...        -1\n",
       "58  Hopefully those jaker assholes. Koreans and Ch...        -1\n",
       "54  Dolphins will play Chargers without four assis...         0\n",
       "97  Coronavirus updates: Thanksgiving NFL games re...        -1\n",
       "51  Andrew Cuomo, who has been far from perfect in...        -1\n",
       "5   #aerosoles #Coronavirus # COVID19 #Spain #Cata...        -1\n",
       "7   Justice for her. This is insane and inhuman Ma...        -1\n",
       "31  I wore a mask and still got #COVID19!  Stupid ...        -1\n",
       "48  Ontario reports record-high 1,588 new COVID-19...        -1\n",
       "52  @gust_avius @firefoxx66 What is happening in #...        -1\n",
       "24  CM ghlot bole- Covid-19 ke lihaaj se cunautii ...        -1\n",
       "0                                           tweetText        -1\n",
       "27  If a family member has been diagnosed with #Co...        -1\n",
       "26  BBC News: Chuck Grassley: Senior Republican se...        -1\n",
       "18  Putin at the BRICS summit: &quot;It is crucial...         0\n",
       "33  Trump-loving pastor contracts COVID-19 after s...        -1\n",
       "10  China accounts for 95 percent of U.S. imports ...        -1\n",
       "43  While over nine in 10 Canadians said they are ...        -1\n",
       "59  Regina perseveres as COVID-19 downsizes Rememb...        -1\n",
       "28                          I hate THIS ENTIRE FAMILY        -1\n",
       "38  can they cancel every other music show next it...        -1\n",
       "74  Here's Everything You Need To Know About BC's ...        -1\n",
       "16                                                OMG        -1\n",
       "60  Well, gentlemen with money will always have th...        -1\n",
       "13           Unbridled capitalism creates sociopaths.        -1\n",
       "94                         A great museum to support!        -1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sample(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5375\n",
      "5330\n",
      "5332\n",
      "5351\n",
      "4898\n",
      "4944\n",
      "4922\n",
      "4903\n",
      "4977\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweetID</td>\n",
       "      <td>tweetTime</td>\n",
       "      <td>tweetText</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1267113249692057606</td>\n",
       "      <td>2020-05-31 15:18:35</td>\n",
       "      <td>@vogon Good Morning Amerikkka     Expect more ...</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1266879605216030721</td>\n",
       "      <td>2020-05-30 23:50:10</td>\n",
       "      <td>The # COVID19 #VaiPassar, CAMPOS DO JORDAO / S...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1258009083577274368</td>\n",
       "      <td>2020-05-06 12:21:52</td>\n",
       "      <td>This is how it was in audiences to Win Sports ...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1261087171273994241</td>\n",
       "      <td>2020-05-15 0:13:06</td>\n",
       "      <td>Nurses are not getting the protections they de...</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 date  \\\n",
       "0              tweetID            tweetTime   \n",
       "1  1267113249692057606  2020-05-31 15:18:35   \n",
       "2  1266879605216030721  2020-05-30 23:50:10   \n",
       "3  1258009083577274368  2020-05-06 12:21:52   \n",
       "4  1261087171273994241   2020-05-15 0:13:06   \n",
       "\n",
       "                                                text  sentiment  \n",
       "0                                          tweetText        0.0  \n",
       "1  @vogon Good Morning Amerikkka     Expect more ...        0.6  \n",
       "2  The # COVID19 #VaiPassar, CAMPOS DO JORDAO / S...        0.0  \n",
       "3  This is how it was in audiences to Win Sports ...        0.4  \n",
       "4  Nurses are not getting the protections they de...       -0.6  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'Jan2021']\n",
    "all_tweets = []\n",
    "for month in months:\n",
    "    filename = 'Tweet Annotations - '+month+' Translated.tsv'\n",
    "    temp_list = tsv_to_list(filename, True)\n",
    "    all_tweets += temp_list\n",
    "\n",
    "full_df = pd.DataFrame(all_tweets, columns=['id', 'date', 'text', 'sentiment'])\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
